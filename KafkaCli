Details
Steps to make progress
1. Create a Topic: 
$ /usr/hdp/current/kafka-broker/bin/kafka-topics.sh --create --zookeeper zookeeeper.example.com:2181 --replication-factor 1 --partitions 2 --topic <TopicName>
Note : number of replication factor cannot be greater than number of brokers.

2. To List the Topic:
$ /usr/hdp/current/kafka-broker/bin/kafka-topics.sh --list --zookeeper zookeeeper.example.com:2181 

3. To describe a topic:
$ /usr/hdp/current/kafka-broker/bin/kafka-topics.sh/kafka-topics.sh --describe --zookeeper  zookeeeper.example.com:2181 --topic <TopicName>

4. Test producer:
$ /usr/hdp/current/kafka-broker/bin/kafka-console-producer.sh --broker-list  kafka.example.com:<port> --topic  <TopicName>

5a. Test consumer (Using old consumer API):
$ /usr/hdp/current/kafka-broker/bin/kafka-console-consumer.sh --zookeeper zookeeeper.example.com:2181  --topic  <TopicName> --from-beginning
5b. Test consumer (Using new consumer API):
$ /usr/hdp/current/kafka-broker/bin/kafka-console-consumer.sh --bootstrap-server   kafka.example.com:<port> --topic <TopicName>

Note : 
If you want to consume messages from the beginning, one needs to append  --from-beginning argument to the above command.
If you want to pass a specific consumer group name to console consumer, create a properties file and add the following entry:
group.id=<GroupName>

and pass the properties file to the command with:
  --consumer.config  <group.properties.file>


6a. List consumer groups (For consumer using old consumer API):
$ /usr/hdp/current/kafka-broker/bin/kafka-consumer-groups.sh  --zookeeper zookeeper.example.com:2181 --list
6b. List consumer groups (For consumers using new consumer API):
$ /usr/hdp/current/kafka-broker/bin/kafka-consumer-groups.sh  --new-consumer --bootstrap-server kafka.example.com:6667 --list 

7a. Describe consumer groups (For consumer using old consumer API):
$ /usr/hdp/current/kafka-broker/bin/kafka-consumer-groups.sh  --zookeeper zookeeper.example.com:2181 --describe --group <GroupName>
7b. Describe consumer groups (For consumers using new consumer API):
$ /usr/hdp/current/kafka-broker/bin/kafka-consumer-groups.sh  --new-consumer --bootstrap-server kafka.example.com:6667 --describe --group <GroupName>

8. To list offset, create time, payload size, and compression codec of each message in partition log file of a topic, use the following command:
$ /usr/hdp/current/kafka-broker/bin/kafka-run-class.sh kafka.tools.DumpLogSegments --deep-iteration --files /kafka-logs/Test-1/00000000000000000000.log
Dumping /kafka-logs/Test-1/00000000000000000000.log
Starting offset: 0
offset: 0 position: 0 CreateTime: 1535971618597 isvalid: true payloadsize: 3 magic: 1 compresscodec: NoCompressionCodec crc: 2156599216
offset: 1 position: 37 CreateTime: 1535972452343 isvalid: true payloadsize: 7 magic: 1 compresscodec: NoCompressionCodec crc: 3793024083
.
.
.
offset: 62 position: 2227 CreateTime: 1535972472454 isvalid: true payloadsize: 2 magic: 1 compresscodec: NoCompressionCodec crc: 3980748776
offset: 63 position: 2263 CreateTime: 1535972472773 isvalid: true payloadsize: 1 magic: 1 compresscodec: NoCompressionCodec crc: 1839237223
NOTE : DumpLogSegments will parse the log file specified.  You can specify multiple log files with a comma separated parameter. 

NOTE: The default log retention policy is 168 hours, so access to information from Kafka logs older than 168 hours is not possible.  If longer retention times are needed, investigate modification of the Kafka Broker log.roll.hours and log.retention.hours parameters in Kafka Broker Settings.

9. To check last offset for all partitions in topic:
$ /usr/hdp/current/kafka-broker/bin/kafka-run-class.sh kafka.tools.GetOffsetShell --broker-list `hostname -f`:6667 --topic Test --time -1  --security-protocol PLAINTEXTSASL
Test:1:64
Test:0:65

10. To check initial offset for all partitions in topic:
$ /usr/hdp/current/kafka-broker/bin//kafka-run-class.sh kafka.tools.GetOffsetShell --broker-list `hostname -f`:6667 --topic Test --time -2  --security-protocol PLAINTEXTSASL
Test:1:0
Test:0:0

11. To print offset information along with payload:
$ /usr/hdp/current/kafka-broker/bin/kafka-run-class.sh kafka.tools.DumpLogSegments --deep-iteration --files /kafka-logs/Test-0/00000000000000000000.log --print-data-log
offset: 0 position: 0 CreateTime: 1535971617204 isvalid: true payloadsize: 2 magic: 1 compresscodec: NoCompressionCodec crc: 394062529 payload: 12
.
.
offset: 55 position: 1974 CreateTime: 1535972470095 isvalid: true payloadsize: 3 magic: 1 compresscodec: NoCompressionCodec crc: 2400170766 payload: raw
